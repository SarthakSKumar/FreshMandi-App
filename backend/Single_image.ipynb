{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding confidence threshold \n",
    "\"\"\"from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vggCapsicumpreprocess_input\n",
    "import numpy as np\n",
    "import os\n",Capsicum
    "from tensorflow.keras.models import load_model\n",
    "\n",Capsicum
    "\n",
    "IMG_SIZE = 224\n",
    "valdir = \"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\\\\Implementation\\\\fruits_vegetables_dataset\\\\validation_data\"\n",
    "types = ['FreshApple', 'FreshBanana','FreshBellpepper', 'FreshCarrot', 'FreshGrape', 'FreshGuava', 'FreshLime', \n",
    "               'FreshOrange', 'FreshPotato', 'FreshTomato', \n",
    "               'RottenApple', 'RottenBanana', 'RottenBellpepper', 'RottenCarrot', 'RottenGrape', 'RottenGuava', \n",
    "               'RottenLime', 'RottenOrange', 'RottenPotato', 'RottenTomato']\n",
    "def calculate_average_confidence_threshold(model, valdir, types, target_size=(IMG_SIZE, IMG_SIZE)):\n",
    "    confidence_scores = []\n",
    "    \n",
    "    # Loop through each type folder in the validation directory\n",
    "    for category in types:\n",Capsicum
    "        type_dir = os.path.join(valdir, category)\n",
    "        if not os.path.isdir(type_dirCapsicum
    "            continue\n",
    "        \n",
    "        # Loop through each image in the type folder\n",
    "        for img_name in os.listdir(type_dir):\n",
    "            img_path = os.path.join(type_dir, img_name)\n",
    "            if img_path.lower().endswith(('.png', '.jpg', '.jpeg', '.jfif', '.webp')):\n",
    "                img = image.load_img(img_path, target_size=target_size)\n",
    "                img_array = image.img_to_array(img)\n",
    "                img_array = preprocess_input(img_array)\n",
    "                img_array = np.expand_dims(img_array, axis=0)\n",
    "                \n",
    "                # Make prediction\n",
    "                predictions = model.predict(img_array)\n",
    "                max_confidence = np.max(predictions)\n",
    "                confidence_scores.append(max_confidence)\n",
    "    \n",
    "    # Calculate the average confidence threshold\n",
    "    average_confidence_threshold = np.mean(confidence_scores)\n",
    "    return average_confidence_threshold\n",
    "\n",
 Capsicum the model\n",
    "model = load_model('tl_model_v2.weights.best.hdf5')\n",
    "\n",
    "# Calculate the average confidence threshold\n",
    "average_confidence_threshold = calculate_average_confidence_threshold(model, valdir, types)\n",
    "print(f\"Average Confidence Threshold: {average_confidence_threshold:.2f}\")\n",
    "\"\"\"\n",
    "# Output : Average Confidence Threshold: 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikie\\anaconda3\\envs\\TDL\\lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:34: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "#new code with price\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import os\n",
    "\n",
    "# Price datasets paths (this can be extended based on the predicted class)\n",
    "price_datasets = {\n",
    "    'FreshApple': \"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\\\\Implementation\\\\price_dataset\\\\Apple.xlsx\",\n",
    "    'FreshBanana': \"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\\\\Implementation\\\\price_dataset\\\\Banana.xlsx\",\n",
    "    'FreshBellpepper': \"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\\\\Implementation\\\\price_dataset\\\\Capsicum.xlsx\",\n",
    "    'FreshCarrot': \"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\\\\Implementation\\\\price_dataset\\\\Carrot.xlsx\",\n",
    "    'FreshGrape': \"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\\\\Implementation\\\\price_dataset\\\\Grapes.xlsx\",\n",
    "    'FreshGuava': \"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\\\\Implementation\\\\price_dataset\\\\Guava.xlsx\",\n",
    "    'FreshLime': \"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\\\\Implementation\\\\price_dataset\\\\Lime.xlsx\",\n",
    "    'FreshOrange': \"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\\\\Implementation\\\\price_dataset\\\\Orange.xlsx\",\n",
    "    'FreshPotato': \"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\\\\Implementation\\\\price_dataset\\\\Potato.xlsx\",\n",
    "    'FreshTomato': \"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\\\\Implementation\\\\price_dataset\\\\Tomato.xlsx\",\n",
    "}\n",
    "\n",
    "IMG_SIZE = 224\n",
    "class_names = [\n",
    "    'FreshApple', 'FreshBanana', 'FreshBellpepper', 'FreshCarrot', 'FreshGrape', \n",
    "    'FreshGuava', 'FreshLime', 'FreshOrange', 'FreshPotato', 'FreshTomato', \n",
    "    'RottenApple', 'RottenBanana', 'RottenBellpepper', 'RottenCarrot', 'RottenGrape', \n",
    "    'RottenGuava', 'RottenLime', 'RottenOrange', 'RottenPotato', 'RottenTomato'\n",
    "]\n",
    "\n",
    "model = load_model('tl_model_v2.weights.best.hdf5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_image_path(img_path):\n",
    "    if not os.path.exists(img_path):\n",
    "        print(\"Error: File does not exist.\")\n",
    "        return False\n",
    "    if not img_path.lower().endswith(('.png', '.jpg', '.jpeg', '.jfif', '.webp')):\n",
    "        print(\"Error: Unsupported file format. Please upload a PNG, JPEG, JPG, JFIF, or WEBP image.\")\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new code for price\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Common date definition\n",
    "date_str = \"24-09-2024\"\n",
    "date = datetime.strptime(date_str, '%d-%m-%Y')  # Convert the date string once\n",
    "\n",
    "# Function to load the price data and predict the price\n",
    "def predict_price(product_name, date):\n",
    "    # Use the passed date in the function\n",
    "    if product_name in price_datasets:\n",
    "        price_file = price_datasets[product_name]\n",
    "        df = pd.read_excel(price_file)\n",
    "\n",
    "        # Ensure 'price date' is in datetime format\n",
    "        df['price date'] = pd.to_datetime(df['price date'], format='%d-%b-%y')\n",
    "\n",
    "        # Filter data for the past three months\n",
    "        start_date = date - timedelta(days=90)  # Approx. 3 months prior\n",
    "        filtered_data = df[(df['price date'] >= start_date) & (df['price date'] <= date)]\n",
    "\n",
    "        if not filtered_data.empty:\n",
    "            # Fit SARIMAX model for price prediction\n",
    "            filtered_data.set_index('price date', inplace=True)\n",
    "            filtered_data = filtered_data.asfreq('D')\n",
    "\n",
    "            sarimax_model = SARIMAX(filtered_data['modal price'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 7), enforce_stationarity=False, enforce_invertibility=False)\n",
    "            sarimax_results = sarimax_model.fit()\n",
    "\n",
    "            # Predict tomorrow's price\n",
    "            #predicted_price = sarimax_results.forecast(steps=1)[0]\n",
    "            predicted_price = sarimax_results.forecast(steps=1).iloc[0]\n",
    "\n",
    "            # Forecast the next 7 days' prices\n",
    "            forecast = sarimax_results.get_forecast(steps=7)\n",
    "            predicted_prices_week = forecast.predicted_mean\n",
    "\n",
    "            # Print tomorrow's price and 7-day forecast\n",
    "            tomorrow_date = date + timedelta(days=1)\n",
    "            print(\"Tomorrow's predicted price ({}): {:.2f}\".format(tomorrow_date.strftime('%d-%m-%Y'), predicted_price))\n",
    "            print(\"7-day price forecast:\")\n",
    "            for i in range(1, 8):\n",
    "                forecast_date = tomorrow_date + timedelta(days=i)\n",
    "                print(\"Price on {}: {:.2f}\".format(forecast_date.strftime('%d-%m-%Y'), predicted_prices_week.iloc[i-1]))\n",
    "\n",
    "            return predicted_price\n",
    "        else:\n",
    "            print(f\"No data available for {product_name} in the given date range.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Price data for {product_name} is not available.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n",
      "Predicted class: FreshApple (Fresh) with confidence 99.95%\n",
      "Tomorrow's predicted price (25-09-2024): 11919.07\n",
      "7-day price forecast:\n",
      "Price on 26-09-2024: 11919.07\n",
      "Price on 27-09-2024: 11933.10\n",
      "Price on 28-09-2024: 11736.61\n",
      "Price on 29-09-2024: 11795.04\n",
      "Price on 30-09-2024: 11801.10\n",
      "Price on 01-10-2024: 11794.02\n",
      "Price on 02-10-2024: 11815.34\n",
      "Predicted price for FreshApple: 11919.07\n",
      "{'result': 'Fresh', 'classification': 1, 'predicted_price': 11919.06978874735}\n"
     ]
    }
   ],
   "source": [
    "# new updae code with price\n",
    "# Modify the predict function to use the common date\n",
    "def predict_single_image(model, img_path, target_size=(224, 224), confidence_threshold=0.98, date=date):\n",
    "    if not validate_image_path(img_path):\n",
    "        return {\"result\": \"Invalid Image Path\", \"classification\": None, \"predicted_price\": None}\n",
    "\n",
    "    try:\n",
    "        # Load and preprocess the image\n",
    "        img = image.load_img(img_path, target_size=target_size)\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        # Make a prediction\n",
    "        predictions = model.predict(img_array)\n",
    "        max_confidence = np.max(predictions)\n",
    "        predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "        predicted_class_name = class_names[predicted_class_index]\n",
    "\n",
    "        # Check if the prediction confidence is above the threshold\n",
    "        if max_confidence >= confidence_threshold:\n",
    "            result = \"Fresh\" if 'Fresh' in predicted_class_name else \"Rotten\"\n",
    "            print(f\"Predicted class: {predicted_class_name} ({result}) with confidence {max_confidence*100:.2f}%\")\n",
    "            classification = 1 if result == \"Fresh\" else 0\n",
    "\n",
    "            # Predict price if the classification is Fresh (1)\n",
    "            predicted_price = None\n",
    "            if classification == 1:  # Only predict price if the item is Fresh\n",
    "                predicted_price = predict_price(predicted_class_name, date)\n",
    "                if predicted_price:\n",
    "                    print(f\"Predicted price for {predicted_class_name}: {predicted_price:.2f}\")\n",
    "            return {\"result\": result, \"classification\": classification, \"predicted_price\": predicted_price}\n",
    "        else:\n",
    "            print(\"The fruit or vegetable uploaded is not confidently classified as any known category.\")\n",
    "            return {\"result\": \"Not Classified\", \"classification\": None, \"predicted_price\": None}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during prediction: {e}\")\n",
    "        return {\"result\": \"Prediction Error\", \"classification\": None, \"predicted_price\": None}\n",
    "\n",
    "# Example usage:\n",
    "new_image_path =\"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\\\\Implementation\\\\Images\\\\fa.png\"\n",
    "prediction_result = predict_single_image(model, new_image_path)\n",
    "\n",
    "# Print the results\n",
    "print(prediction_result)\n",
    "\n",
    "#apple  train/test/val red apples \n",
    "#banana  done\n",
    "#bellpepper done\n",
    "#carrot done\n",
    "#grapes   price\n",
    "#guava   price\n",
    "#lime    price+ images shld be train/test/val dataset\n",
    "#orange done\n",
    "#potato done\n",
    "#tomato done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old code only with freshness\n",
    "\"\"\"\n",
    "def predict_single_image(model, img_path, target_size=(IMG_SIZE, IMG_SIZE), confidence_threshold=0.98):\n",
    "\n",
    "    if not validate_image_path(img_path):\n",
    "        return \"Invalid Image Path\", None\n",
    "\n",
    "    try:\n",
    "        # Load and preprocess the image\n",
    "        img = image.load_img(img_path, target_size=target_size)\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        # Make a prediction\n",
    "        predictions = model.predict(img_array)\n",
    "        max_confidence = np.max(predictions)\n",
    "        predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "        predicted_class_name = class_names[predicted_class_index]\n",
    "        \n",
    "        # Check if the prediction confidence is above the threshold\n",
    "        if max_confidence >= confidence_threshold:\n",
    "            result = \"Fresh\" if 'Fresh' in predicted_class_name else \"Rotten\"\n",
    "            print(f\"Predicted class: {predicted_class_name} ({result}) with confidence {max_confidence*100:.2f}%\")\n",
    "            classification = 1 if result == \"Fresh\" else 0\n",
    "            return result, classification\n",
    "        else:\n",
    "            print(\"The fruit or vegetable uploaded is not confidently classified as any known category.\")\n",
    "            return \"Not Classified\", None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during prediction: {e}\")\n",
    "        return \"Prediction Error\", None\n",
    "\n",
    "new_image_path = \"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\\\\Implementation\\\\Images\\\\fl.jpg\"\n",
    "result, classification = predict_single_image(model, new_image_path)\n",
    "\n",
    "print(f\"Result: {result}, Classification: {classification}\")\"\"\"\n",
    "\n",
    "\n",
    "# Outputs\n",
    "## mango->not classified\n",
    "## watermelon->not classified\n",
    "## strawberry->bp (rotten correct) 99.99\n",
    "## Bitter gourd not classified \n",
    "\n",
    "## Rotten Carrot 100\n",
    "## rotten tomato  100\n",
    "## fresh orange 100\n",
    "## fresh guava 100\n",
    "## fresh bp 99.84\n",
    "## fresh banana 99.80\n",
    "## fresh grapes 98.84\n",
    "## rg-> rotten apple 100 (green apple)\n",
    "## fr->fresh apple 100 (green apple)\n",
    "## fresh potato(pppp) 100\n",
    "## rotten potato (rp) 100\n",
    "\n",
    "## Misclassification\n",
    "## apple->rotten tomato 99.85 ## aa,gg,images,ff,rr not classified  -> apples rotten\n",
    "## potato pp not classified\n",
    "## download,fl  ->lime not classified\n",
    "## ll->fresh apple not classified\n",
    "## lll->fresh orange (lime) 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fresh Analysis Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from skimage.feature import local_binary_pattern\n",
    "from scipy.ndimage import gaussian_laplace\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Enhanced Color Feature Extraction\n",
    "def extract_color_features(image):\n",
    "    try:\n",
    "        # Split into HSV (Hue, Saturation, Value) color space\n",
    "        hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv_image)\n",
    "\n",
    "        # Compute mean, std, skew, and kurtosis in HSV channels\n",
    "        h_mean, h_std, h_skew, h_kurt = np.mean(h), np.std(h), skew(h.flatten()), kurtosis(h.flatten())\n",
    "        s_mean, s_std, s_skew, s_kurt = np.mean(s), np.std(s), skew(s.flatten()), kurtosis(s.flatten())\n",
    "        v_mean, v_std, v_skew, v_kurt = np.mean(v), np.std(v), skew(v.flatten()), kurtosis(v.flatten())\n",
    "\n",
    "        # Combine color features\n",
    "        color_features = [h_mean, s_mean, v_mean, h_std, s_std, v_std, h_skew, s_skew, v_skew, h_kurt, s_kurt, v_kurt]\n",
    "\n",
    "        #print(\"extracted rgb features\")\n",
    "\n",
    "        return np.array(color_features)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting color features: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Enhanced Texture Feature Extraction using Local Binary Patterns\n",
    "def extract_texture_features(image):\n",
    "    try:\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Apply Local Binary Pattern (LBP) for texture analysis\n",
    "        radius = 3  # LBP radius\n",
    "        n_points = 8 * radius  # Number of points considered in LBP\n",
    "        lbp = local_binary_pattern(gray_image, n_points, radius, method='uniform')\n",
    "        n_bins = int(lbp.max() + 1)\n",
    "\n",
    "        # Compute the histogram of LBP values\n",
    "        lbp_hist, _ = np.histogram(lbp, bins=n_bins, range=(0, n_bins), density=True)\n",
    "\n",
    "        #print(\"extracted texture features\")\n",
    "\n",
    "        return lbp_hist\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting texture features: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract LoG features\n",
    "def extract_edge_features(image, sigma=0.55):\n",
    "    try:\n",
    "        # Resize the image to a fixed size, e.g., 128x128\n",
    "        fixed_size = (128, 128)\n",
    "        image_resized = cv2.resize(image, fixed_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Step 1: Bilateral Filtering for noise reduction while preserving edges\n",
    "        image_filtered = cv2.bilateralFilter(image_resized, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "        \n",
    "        # Step 2: Gaussian Blur for further smoothing\n",
    "        image_blurred = cv2.GaussianBlur(image_filtered, (5, 5), 0)\n",
    "        \n",
    "        # Convert the resized image to grayscale\n",
    "        gray_image = cv2.cvtColor(image_blurred, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply Laplacian of Gaussian (LoG) with the specified sigma\n",
    "        log_image = gaussian_laplace(gray_image, sigma=sigma)\n",
    "        \n",
    "        # Flatten and standardize the features\n",
    "        features = log_image.flatten()\n",
    "        if features.size > 0:\n",
    "            mean = np.mean(features)\n",
    "            std_dev = np.std(features)\n",
    "            if std_dev > 0:\n",
    "                features = (features - mean) / std_dev\n",
    "            else:\n",
    "                print(\"Warning: Standard deviation is zero, skipping standardization.\")\n",
    "        \n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract LoG features: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained classifiers\n",
    "def load_classifier(filename):\n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            classifier = pickle.load(f)\n",
    "        print(f\"Classifier successfully loaded from {filename}\")\n",
    "        return classifier\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load classifier from {filename}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights and shelf life mapping\n",
    "weights = {'texture': 0.3516, 'color': 0.3989, 'edge': 0.2496}\n",
    "shelf_life_mapping = {\n",
    "    'Fresh': (7, 10),      \n",
    "    'ShelfLife': (3, 7),   \n",
    "    'Rotten': (0, 3)\n",
    "}\n",
    "# Function to calculate shelf life in days\n",
    "def calculate_shelf_life(shelf_life_index, category):\n",
    "    min_days, max_days = shelf_life_mapping[category]\n",
    "    return min_days + (max_days - min_days) * shelf_life_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
      "Predicted class: FreshApple (Fresh) with confidence 99.95%\n",
      "Tomorrow's predicted price (25-09-2024): 11919.07\n",
      "7-day price forecast:\n",
      "Price on 26-09-2024: 11919.07\n",
      "Price on 27-09-2024: 11933.10\n",
      "Price on 28-09-2024: 11736.61\n",
      "Price on 29-09-2024: 11795.04\n",
      "Price on 30-09-2024: 11801.10\n",
      "Price on 01-10-2024: 11794.02\n",
      "Price on 02-10-2024: 11815.34\n",
      "Predicted price for FreshApple: 11919.07\n",
      "Classifier successfully loaded from C:\\Users\\nikie\\Desktop\\Capstone\\texture_classifier_train.pkl\n",
      "Classifier successfully loaded from C:\\Users\\nikie\\Desktop\\Capstone\\color_classifier_train.pkl\n",
      "Classifier successfully loaded from C:\\Users\\nikie\\Desktop\\Capstone\\edge_classifier_train.pkl\n",
      "Tomorrow's fair price (25-09-2024): 11859.47\n",
      "Generating a 7-day fair price forecast...\n",
      "Fair Price forecast for the upcoming week:\n",
      "Fair Price on 26-09-2024: 11978.07\n",
      "Fair Price on 27-09-2024: 12096.66\n",
      "Fair Price on 28-09-2024: 12215.26\n",
      "Fair Price on 29-09-2024: 12333.85\n",
      "Fair Price on 30-09-2024: 12452.45\n",
      "Fair Price on 01-10-2024: 12571.04\n",
      "Fair Price on 02-10-2024: 12689.64\n",
      "Texture Score: 0.94\n",
      "Color Score: 0.96\n",
      "Edge Score: 0.93\n",
      "Freshness Index: 0.95\n",
      "Predicted Category: Fresh\n",
      "Shelf Life Days: 10\n"
     ]
    }
   ],
   "source": [
    "#new updated with price code\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def process_single_image(image_path):\n",
    "    # Step 1: Use the deep learning model to predict Fresh or Rotten\n",
    "    prediction_result = predict_single_image(model, image_path)\n",
    "    result = prediction_result['result']\n",
    "    classification = prediction_result['classification']\n",
    "    predicted_price = prediction_result['predicted_price']\n",
    "\n",
    "    # Handle case where price prediction is not available\n",
    "    if predicted_price is None:\n",
    "        print(\"Price prediction not available.\")\n",
    "        return\n",
    "\n",
    "    if result == \"Fresh\" and classification == 1:\n",
    "        base_dir = \"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\"\n",
    "\n",
    "        # Load classifiers\n",
    "        texture_classifier = load_classifier(os.path.join(base_dir, 'texture_classifier_train.pkl'))\n",
    "        color_classifier = load_classifier(os.path.join(base_dir, 'color_classifier_train.pkl'))\n",
    "        edge_classifier = load_classifier(os.path.join(base_dir, 'edge_classifier_train.pkl'))\n",
    "\n",
    "        if any(clf is None for clf in [texture_classifier, color_classifier, edge_classifier]):\n",
    "            print(\"One or more classifiers failed to load. Please ensure all pickle files exist.\")\n",
    "            return\n",
    "\n",
    "        # Load and process the image\n",
    "        image_cv = cv2.imread(image_path)\n",
    "        if image_cv is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "            return\n",
    "\n",
    "        # Extract features\n",
    "        color_features = extract_color_features(image_cv)\n",
    "        texture_features = extract_texture_features(image_cv)\n",
    "        edge_features = extract_edge_features(image_cv)\n",
    "\n",
    "        if any(feat is None for feat in [color_features, texture_features, edge_features]):\n",
    "            print(\"Feature extraction failed for the image.\")\n",
    "            return\n",
    "\n",
    "        # Calculate scores using each classifier's probability predictions\n",
    "        texture_score = texture_classifier.predict_proba([texture_features])[0, 1] if hasattr(texture_classifier, \"predict_proba\") else 0\n",
    "        color_score = color_classifier.predict_proba([color_features])[0, 1] if hasattr(color_classifier, \"predict_proba\") else 0\n",
    "        edge_score = edge_classifier.predict_proba([edge_features])[0, 1] if hasattr(edge_classifier, \"predict_proba\") else 0\n",
    "\n",
    "        # Compute freshness index\n",
    "        freshness_index = round(weights['texture'] * texture_score +\n",
    "                                weights['color'] * color_score +\n",
    "                                weights['edge'] * edge_score, 2)\n",
    "                                 \n",
    "        # Define thresholds for freshness index\n",
    "        upper_threshold = 0.8934887673815148\n",
    "        lower_threshold = 0.46346304980538544\n",
    "\n",
    "        # Determine category and calculate shelf life index and days\n",
    "        if freshness_index >= upper_threshold:\n",
    "            predicted_category = 'Fresh'\n",
    "            shelf_life_index = np.nan\n",
    "            shelf_life_days = '10'\n",
    "        elif freshness_index <= lower_threshold:\n",
    "            predicted_category = 'Rotten'\n",
    "            shelf_life_index = np.nan\n",
    "            shelf_life_days = 'Manure ingredient'\n",
    "        else:\n",
    "            predicted_category = 'ShelfLife'\n",
    "            shelf_life_index = round((freshness_index - lower_threshold) / (upper_threshold - lower_threshold), 2)\n",
    "            shelf_life_days = round(calculate_shelf_life(shelf_life_index, 'ShelfLife')) \n",
    "\n",
    "        # Calculate tomorrow's predicted fair price\n",
    "        fair_price = predicted_price * (0.9 + 0.1 * freshness_index)  # Adjust fair price based on freshness index\n",
    "        # Set the base date for forecasting (aligned with SARIMAX predictions)\n",
    "        base_date = date + timedelta(days=1)\n",
    "        # Print tomorrow's price\n",
    "        print(\"Tomorrow's fair price ({}): {:.2f}\".format(base_date.strftime('%d-%m-%Y'), fair_price))\n",
    "    \n",
    "        # Forecasting for the next 7 days\n",
    "        print(\"Generating a 7-day fair price forecast...\")\n",
    "        predicted_prices_week = []\n",
    "        forecast_dates = []  # List to store forecast dates\n",
    "        for i in range(1,8):\n",
    "            # Adjust the fair price slightly for each day\n",
    "            adjusted_fair_price = fair_price * (1+ (0.01 * i))  # Adjust by 1% per day\n",
    "            predicted_prices_week.append(adjusted_fair_price)\n",
    "\n",
    "            # Calculate the corresponding forecast date\n",
    "            forecast_date = base_date + timedelta(days=i)\n",
    "            forecast_dates.append(forecast_date)\n",
    "\n",
    "        # Print the 7-day forecast\n",
    "        print(\"Fair Price forecast for the upcoming week:\")\n",
    "        for i, forecast_date in enumerate(forecast_dates):\n",
    "            print(f\"Fair Price on {forecast_date.strftime('%d-%m-%Y')}: {predicted_prices_week[i]:.2f}\")\n",
    "            \n",
    "        # Print results\n",
    "        print(f\"Texture Score: {texture_score:.2f}\")\n",
    "        print(f\"Color Score: {color_score:.2f}\")\n",
    "        print(f\"Edge Score: {edge_score:.2f}\")\n",
    "        print(f\"Freshness Index: {freshness_index:.2f}\")\n",
    "        print(f\"Predicted Category: {predicted_category}\")\n",
    "        print(f\"Shelf Life Days: {shelf_life_days}\")\n",
    "    else:\n",
    "        print(f\"Deep learning model final classification: {result}\")\n",
    "\n",
    "# Example usage\n",
    "process_single_image(\"C:\\\\Users\\\\nikie\\\\Desktop\\\\Capstone\\\\Implementation\\\\Images\\\\fa.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
